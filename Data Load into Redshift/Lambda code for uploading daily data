import boto3
import psycopg2
import logging

# Set up logging to view the status of redshift connection and data uploading
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def lambda_handler(event, context):
    try:
        bucket_name = event['Records'][0]['s3']['bucket']['name']
        file_key = event['Records'][0]['s3']['object']['key']
        logger.info(f"Processing file: s3://{bucket_name}/{file_key}")

        s3 = boto3.client('s3')
        obj = s3.get_object(Bucket=bucket_name, Key=file_key)
        csv_data = obj['Body'].read().decode('utf-8')
        logger.info(f"Successfully retrieved data from S3 bucket: {bucket_name}")

        # Connect to Redshift
        conn = psycopg2.connect(
            dbname='dev',
            user='awsuser1',
            password='Redshift1',
            host='redshift-cluster-1.cob9zzlbccm1.ap-south-1.redshift.amazonaws.com',
            port='5439'
        )
        cur = conn.cursor()
        logger.info("Successfully connected to Redshift")

        # Upload data to historic data table
        copy_cmd_1 = f"""
        COPY historicdata
        FROM 's3://{bucket_name}/{file_key}'
        CREDENTIALS 'aws_access_key_id=access_key;aws_secret_access_key=secret_access_key' # the access keys have been changed due to upload issues
        CSV
        IGNOREHEADER 1;
        """
        cur.execute(copy_cmd_1)
        conn.commit()
        logger.info("Data successfully loaded into table 'historicdata'")

        # Upload data to mf data table (data from 2018)
        copy_cmd_2 = f"""
        COPY mfdata
        FROM 's3://{bucket_name}/{file_key}'
        CREDENTIALS 'aws_access_key_id=access_key;aws_secret_access_key=secret_access_key' # the access keys have been changed due to upload issues
        CSV
        IGNOREHEADER 1;
        """
        cur.execute(copy_cmd_2)
        conn.commit()
        logger.info("Data successfully loaded into table 'mfdata'")

        cur.close()
        conn.close()
        logger.info("Redshift connection closed successfully")

        return {
            'statusCode': 200,
            'body': 'Data loaded successfully'
        }

    except Exception as e:
        logger.error(f"Error processing file: {e}")
        return {
            'statusCode': 500,
            'body': f'Error: {e}'
        }

